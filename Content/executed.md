# ğŸ› ï¸ Project Execution: Terraform 3-Tier Employee Directory Application

Welcome to the **hands-on execution log** of my Terraform 3-Tier Employee Directory Web Application project.

This file documents **what I actually did** â€” from Module 0 (state setup) through Module 7 (ALB + Auto Scaling) â€” including:

âœ… **Terraform commands run** (`init`, `plan`, `apply`)
ğŸ“œ **Snippets of `.tf` code** for each AWS resource
ğŸ–¼ï¸ **Screenshots** from AWS Console for visual proof
ğŸ§ª **Tests and validations** of deployed infrastructure
ğŸ’¡ **Lessons learned** and troubleshooting notes
ğŸ“¦ **Cleanup** steps after each module to save costs

---

## ğŸ“‹ Execution Modules

* **Module 0** â€“ Local & Remote State Setup (S3 + DynamoDB)
* **Module 1** â€“ Global Project Setup (Provider, Tags, Variables)
* **Module 2** â€“ IAM (Users, Groups, Roles, Policies)
* **Module 3** â€“ EC2 (Web Server Deployment)
* **Module 4** â€“ VPC & Networking
* **Module 5** â€“ S3 (Profile Photo Storage)
* **Module 6** â€“ DynamoDB (Employee Records)
* **Module 7** â€“ ALB + Auto Scaling

---

## ğŸ› ï¸ Module 0 â€” Local & Remote State Setup

**Goal:**
Create S3 bucket + DynamoDB table via Terraform for storing and locking Terraform state.

**Terraform Steps Taken:**

1. Created `variables.tf` for:

   * `state_bucket_name`
   * `state_dynamodb_table`
   * `aws_region`
   * `tags`
2. Wrote `main.tf` to:

   * Create S3 bucket with versioning
   * Create DynamoDB table with primary key `LockID`
3. Configured backend in `terraform` block to use the above S3/DynamoDB.
4. Ran:

   ```bash
   terraform init
   terraform apply
   ```
5. Verified in AWS Console: S3 bucket exists + DynamoDB table created.

**Validation Checklist:**

* [ ] S3 bucket versioning enabled
* [ ] DynamoDB table has `LockID` key
* [ ] `terraform plan` works without backend errors

**Lessons Learned:**
*(Write after running â€” e.g., â€œHad to enable `force_destroy` in S3 for cleanup.â€)*

---

## ğŸŒ Module 1 â€” Global Project Setup

**Goal:**
Configure AWS provider, default tags, and global variables.

**Terraform Steps Taken:**

1. Defined variables in `variables.tf`:

   * `aws_region`
   * `project_name`
   * `environment`
   * `tags`
2. Configured AWS provider block with default tags.
3. Tested provider connection:

   ```bash
   terraform plan
   ```

**Validation Checklist:**

* [ ] Provider loads correct region
* [ ] Tags applied to all resources

**Lessons Learned:**
*(Write after running)*

---

## ğŸ” Module 2 â€” IAM

**Goal:**
Create IAM users, group, EC2 role, and attach policies.

**Terraform Steps Taken:**

* Created `iam.tf` to define:

  * Users `${var.admin_user_name}` & `${var.dev_user_name}`
  * Group `${var.iam_group_name}`
  * Role `${var.ec2_role_name}` with EC2 trust
  * Managed policies from variables
  * Instance profile

**Validation Checklist:**

* [ ] Users visible in AWS IAM
* [ ] Group with correct policies exists
* [ ] Role attached to EC2 instance profile

---

## ğŸŒ Module 3 â€” EC2

**Goal:**
Launch EC2 instance for the Flask app with IAM role and security group.

**Terraform Steps Taken:**

* Used `data "aws_ami"` to find Amazon Linux 2023.
* Created `aws_instance` with:

  * `user_data` from `scripts/user_data.sh`
  * IAM instance profile from Module 2
* Allowed HTTP/HTTPS inbound from `${var.web_ingress_cidrs}`

**Validation Checklist:**

* [ ] EC2 launches without errors
* [ ] App accessible via public IP
* [ ] IAM role attached correctly

---

## ğŸ—ï¸ Module 4 â€” VPC & Networking

**Goal:**
Deploy custom VPC with public/private subnets, IGW, and route tables.

**Terraform Steps Taken:**

* Created `vpc.tf` for:

  * VPC with CIDR `${var.vpc_cidr}`
  * Public/private subnets
  * Internet Gateway
  * Public route table associations

**Validation Checklist:**

* [ ] Subnets correctly tagged as public/private
* [ ] Public subnet has internet access

---

## ğŸª£ Module 5 â€” S3

**Goal:**
Set up S3 bucket for employee profile photos, restricted to EC2 role.

**Terraform Steps Taken:**

* Created `s3.tf`:

  * S3 bucket `${var.photos_bucket_name}`
  * Public access blocked
  * Bucket policy allowing only `${var.ec2_role_name}` to Put/Get

**Validation Checklist:**

* [ ] Bucket exists and blocks public access
* [ ] EC2 can upload & retrieve photos

---

## ğŸ“„ Module 6 â€” DynamoDB

**Goal:**
Store employee records in DynamoDB table with PAY\_PER\_REQUEST billing.

**Terraform Steps Taken:**

* Created `dynamodb.tf`:

  * Table `${var.ddb_table_name}` with key `${var.ddb_hash_key}`
  * IAM policy for EC2 CRUD access

**Validation Checklist:**

* [ ] Table exists in AWS
* [ ] App can read/write records

---

## âš–ï¸ Module 7 â€” ALB + Auto Scaling

**Goal:**
Add load balancer and scale EC2 instances automatically.

**Terraform Steps Taken:**

* Created `alb.tf` and `asg.tf`:

  * ALB in public subnets
  * Target group for app
  * Launch template for EC2
  * Auto Scaling Group with CPU target policy

**Validation Checklist:**

* [ ] ALB distributes traffic evenly
* [ ] Auto scaling triggers on CPU load

---

## ğŸ” Why Document Execution?

Writing this log was part of my **learn-by-building** approach.
I didnâ€™t just read Terraform docs â€” I **coded, deployed, tested, broke things, fixed them**, and learned why each resource mattered.

If youâ€™re learning Terraform, prepping for the **Terraform Associate** exam, or building similar AWS stacks â€” this execution log is for you.

